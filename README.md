# Just 

## Session 1 
### Querying Database

- Please find [Session 1](SESSION_1) folder.
- There will be 3 files where you can check the DB Schema, DB Sample Data, DB Queries.
- MSSQL Server 

## Session 2
### Database Modeling


## Session 3
### Python Code Challenges

- Please find [Session 3](SESSION_2) folder.
- [First Challenge](SESSION_3/truthy_osome.py): 
  - Retrieve data from open source api https://www.programmableweb.com/api/truthy-osome-rest-api  and write the data to a suitable location so it can be used for reporting. The data should be modelled in such a way that it is easy for a user to access.
- [Second Challenge](SESSION_3/just_guardian_scraping.py):
  - Create a solution that crawls for articles for articles from a news website (e.g. https://www.bbc.co.uk/ or https://www.theguardian.com/uk/london), cleanses the responses and then stores the data responses in a SQLLite database. You should look to scrap info reading at least 100 articles and the data stored in the SQL Lite database should contain the article title, text, date of article and source URL.
